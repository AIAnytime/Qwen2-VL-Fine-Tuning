{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fDRt541HG2lk",
        "outputId": "cbde619c-c66f-40ab-8979-8d1d95668752"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'LLaMA-Factory'...\n",
            "remote: Enumerating objects: 17021, done.\u001b[K\n",
            "remote: Counting objects: 100% (765/765), done.\u001b[K\n",
            "remote: Compressing objects: 100% (368/368), done.\u001b[K\n",
            "remote: Total 17021 (delta 533), reused 556 (delta 397), pack-reused 16256 (from 1)\u001b[K\n",
            "Receiving objects: 100% (17021/17021), 225.64 MiB | 28.30 MiB/s, done.\n",
            "Resolving deltas: 100% (12429/12429), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/hiyouga/LLaMA-Factory.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd LLaMA-Factory"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n5bIDKpDHHds",
        "outputId": "cd28b2fe-7ca3-43fb-e04f-08211a089a46"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_KiokYbHUOc",
        "outputId": "c30d9cbe-c830-4069-8068-ec6623b29d65"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -r requirements.txt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "NyJuEvn4HU-h",
        "outputId": "cd657e78-7454-432c-f0cb-fa8376446c7f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 1)) (4.44.2)\n",
            "Collecting datasets<=2.21.0,>=2.16.0 (from -r requirements.txt (line 2))\n",
            "  Downloading datasets-2.21.0-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: accelerate<=0.33.0,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 3)) (0.33.0)\n",
            "Collecting peft<=0.12.0,>=0.11.1 (from -r requirements.txt (line 4))\n",
            "  Downloading peft-0.12.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting trl<=0.9.6,>=0.8.6 (from -r requirements.txt (line 5))\n",
            "  Downloading trl-0.9.6-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting gradio>=4.0.0 (from -r requirements.txt (line 6))\n",
            "  Downloading gradio-4.43.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 7)) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 8)) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 9)) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 10)) (0.1.99)\n",
            "Collecting tiktoken (from -r requirements.txt (line 11))\n",
            "  Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 12)) (3.20.3)\n",
            "Collecting uvicorn (from -r requirements.txt (line 13))\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 14)) (2.8.2)\n",
            "Collecting fastapi (from -r requirements.txt (line 15))\n",
            "  Downloading fastapi-0.114.0-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting sse-starlette (from -r requirements.txt (line 16))\n",
            "  Downloading sse_starlette-2.1.3-py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 17)) (3.7.1)\n",
            "Collecting fire (from -r requirements.txt (line 18))\n",
            "  Downloading fire-0.6.0.tar.gz (88 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m88.4/88.4 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 19)) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 20)) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from -r requirements.txt (line 21)) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.24.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (4.66.5)\n",
            "Collecting pyarrow>=15.0.0 (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.3 kB)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting xxhash (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2))\n",
            "  Downloading multiprocess-0.70.16-py310-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (3.10.5)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.33.0,>=0.30.1->-r requirements.txt (line 3)) (5.9.5)\n",
            "Requirement already satisfied: torch>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.33.0,>=0.30.1->-r requirements.txt (line 3)) (2.4.0+cu121)\n",
            "Collecting tyro>=0.5.11 (from trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading tyro-0.8.10-py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.7.1)\n",
            "Collecting fastapi (from -r requirements.txt (line 15))\n",
            "  Downloading fastapi-0.112.4-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading httpx-0.27.2-py3-none-any.whl.metadata (7.1 kB)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (6.4.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.1.5)\n",
            "Collecting orjson~=3.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (9.4.0)\n",
            "Collecting pydub (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting ruff>=0.2.2 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading ruff-0.6.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->-r requirements.txt (line 6)) (2.0.7)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->-r requirements.txt (line 7)) (2024.1)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->-r requirements.txt (line 13)) (8.1.7)\n",
            "Collecting h11>=0.8 (from uvicorn->-r requirements.txt (line 13))\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->-r requirements.txt (line 14)) (2.20.1)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->-r requirements.txt (line 15))\n",
            "  Downloading starlette-0.38.4-py3-none-any.whl.metadata (6.0 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->-r requirements.txt (line 17)) (3.1.4)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 18)) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->-r requirements.txt (line 18)) (2.4.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->-r requirements.txt (line 6)) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->-r requirements.txt (line 2)) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6)) (2024.8.30)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio>=4.0.0->-r requirements.txt (line 6))\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers<=4.45.0,>=4.41.2->-r requirements.txt (line 1)) (3.3.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->-r requirements.txt (line 3)) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->-r requirements.txt (line 3)) (3.3)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (13.8.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5)) (0.16)\n",
            "Collecting shtab>=1.5.6 (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->-r requirements.txt (line 5))\n",
            "  Downloading shtab-1.7.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (2.16.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.10.0->accelerate<=0.33.0,>=0.30.1->-r requirements.txt (line 3)) (1.3.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->-r requirements.txt (line 6)) (0.1.2)\n",
            "Downloading datasets-2.21.0-py3-none-any.whl (527 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.3/527.3 kB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading peft-0.12.0-py3-none-any.whl (296 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m296.4/296.4 kB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading trl-0.9.6-py3-none-any.whl (245 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m245.8/245.8 kB\u001b[0m \u001b[31m20.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio-4.43.0-py3-none-any.whl (18.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.1/18.1 MB\u001b[0m \u001b[31m74.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading tiktoken-0.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m63.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.4-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sse_starlette-2.1.3-py3-none-any.whl (9.4 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpx-0.27.2-py3-none-any.whl (76 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.4/76.4 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-17.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (39.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.9/39.9 MB\u001b[0m \u001b[31m45.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.4-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m84.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading starlette-0.38.4-py3-none-any.whl (71 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.4/71.4 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tyro-0.8.10-py3-none-any.whl (105 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading multiprocess-0.70.16-py310-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m13.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading xxhash-3.5.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.1/194.1 kB\u001b[0m \u001b[31m17.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading shtab-1.7.1-py3-none-any.whl (14 kB)\n",
            "Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m12.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: fire\n",
            "  Building wheel for fire (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for fire: filename=fire-0.6.0-py2.py3-none-any.whl size=117030 sha256=59a8ee436bfe1d80f293d2a7c39034c70d9950af581b35eeb87641908d795f56\n",
            "  Stored in directory: /root/.cache/pip/wheels/d6/6d/5d/5b73fa0f46d01a793713f8859201361e9e581ced8c75e5c6a3\n",
            "Successfully built fire\n",
            "Installing collected packages: pydub, xxhash, websockets, tomlkit, shtab, semantic-version, ruff, python-multipart, pyarrow, orjson, h11, fire, ffmpy, dill, aiofiles, uvicorn, tiktoken, starlette, multiprocess, httpcore, tyro, sse-starlette, httpx, fastapi, gradio-client, datasets, trl, peft, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 17.0.0 which is incompatible.\n",
            "ibis-framework 8.0.0 requires pyarrow<16,>=2, but you have pyarrow 17.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed aiofiles-23.2.1 datasets-2.21.0 dill-0.3.8 fastapi-0.112.4 ffmpy-0.4.0 fire-0.6.0 gradio-4.43.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.2 multiprocess-0.70.16 orjson-3.10.7 peft-0.12.0 pyarrow-17.0.0 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.4 semantic-version-2.10.0 shtab-1.7.1 sse-starlette-2.1.3 starlette-0.38.4 tiktoken-0.7.0 tomlkit-0.12.0 trl-0.9.6 tyro-0.8.10 uvicorn-0.30.6 websockets-12.0 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pyarrow"
                ]
              },
              "id": "6a9b87d0659142c2ac26e32c1b6d4734"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install bitsandbytes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQOME_2YHbYi",
        "outputId": "99fd22b7-202d-4360-e298-366ff060dbda"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bitsandbytes\n",
            "  Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (2.4.0+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from bitsandbytes) (1.26.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->bitsandbytes) (2024.6.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->bitsandbytes) (2.1.5)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->bitsandbytes) (1.3.0)\n",
            "Downloading bitsandbytes-0.43.3-py3-none-manylinux_2_24_x86_64.whl (137.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m137.5/137.5 MB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: bitsandbytes\n",
            "Successfully installed bitsandbytes-0.43.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "asmDT8YnQ81j",
        "outputId": "7fd83089-9fc8-4317-b6c6-3e8d4f341cfe"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/huggingface/transformers.git\n",
            "  Cloning https://github.com/huggingface/transformers.git to /tmp/pip-req-build-_cz37c36\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/huggingface/transformers.git /tmp/pip-req-build-_cz37c36\n",
            "  Resolved https://github.com/huggingface/transformers.git to commit 66bc4def9505fa7c7fe4aa7a248c34a026bb552b\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.19.1)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (0.4.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.45.0.dev0) (4.66.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (2024.6.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.45.0.dev0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers==4.45.0.dev0) (2024.8.30)\n",
            "Building wheels for collected packages: transformers\n",
            "  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for transformers: filename=transformers-4.45.0.dev0-py3-none-any.whl size=9680506 sha256=9bfc2236589de75419e092b60b5d14d35646fa7f7bccc8fd9fca9c23ef99fd6e\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-10bog6_r/wheels/e7/9c/5b/e1a9c8007c343041e61cc484433d512ea9274272e3fcbe7c16\n",
            "Successfully built transformers\n",
            "Installing collected packages: transformers\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.44.2\n",
            "    Uninstalling transformers-4.44.2:\n",
            "      Successfully uninstalled transformers-4.44.2\n",
            "Successfully installed transformers-4.45.0.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -e \".[torch,metrics]\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-xK_FdtOLM5F",
        "outputId": "5e344d26-d0fa-47ce-bdb2-9fc4d53d11bf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/LLaMA-Factory\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: transformers<=4.45.0,>=4.41.2 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (4.44.2)\n",
            "Requirement already satisfied: datasets<=2.21.0,>=2.16.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (2.21.0)\n",
            "Requirement already satisfied: accelerate<=0.33.0,>=0.30.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.33.0)\n",
            "Requirement already satisfied: peft<=0.12.0,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.12.0)\n",
            "Requirement already satisfied: trl<=0.9.6,>=0.8.6 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.9.6)\n",
            "Requirement already satisfied: gradio>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (4.43.0)\n",
            "Requirement already satisfied: pandas>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (2.1.4)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (1.13.1)\n",
            "Requirement already satisfied: einops in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.8.0)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.1.99)\n",
            "Requirement already satisfied: tiktoken in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.7.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (3.20.3)\n",
            "Requirement already satisfied: uvicorn in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.30.6)\n",
            "Requirement already satisfied: pydantic in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (2.8.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.112.4)\n",
            "Requirement already satisfied: sse-starlette in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (2.1.3)\n",
            "Requirement already satisfied: matplotlib>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (3.7.1)\n",
            "Requirement already satisfied: fire in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.6.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (24.1)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (6.0.2)\n",
            "Requirement already satisfied: numpy<2.0.0 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (1.26.4)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (3.8.1)\n",
            "Requirement already satisfied: jieba in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (0.42.1)\n",
            "Requirement already satisfied: rouge-chinese in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (1.0.3)\n",
            "Requirement already satisfied: torch>=1.13.1 in /usr/local/lib/python3.10/dist-packages (from llamafactory==0.8.4.dev0) (2.4.0+cu121)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.8.4.dev0) (5.9.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.8.4.dev0) (0.24.6)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from accelerate<=0.33.0,>=0.30.1->llamafactory==0.8.4.dev0) (0.4.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (3.15.4)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (17.0.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (0.3.8)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (4.66.5)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (3.10.5)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (23.2.1)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (3.7.1)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.4.0)\n",
            "Requirement already satisfied: gradio-client==1.3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.27.2)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (6.4.4)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (2.1.5)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (3.10.7)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (9.4.0)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.0.9)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.6.4)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.12.0)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.12.5)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio>=4.0.0->llamafactory==0.8.4.dev0) (2.0.7)\n",
            "Requirement already satisfied: websockets<13.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio>=4.0.0->llamafactory==0.8.4.dev0) (12.0)\n",
            "Requirement already satisfied: starlette<0.39.0,>=0.37.2 in /usr/local/lib/python3.10/dist-packages (from fastapi->llamafactory==0.8.4.dev0) (0.38.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (3.1.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.7.0->llamafactory==0.8.4.dev0) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.8.4.dev0) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=2.0.0->llamafactory==0.8.4.dev0) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.8.4.dev0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic->llamafactory==0.8.4.dev0) (2.20.1)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.8.4.dev0) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.1->llamafactory==0.8.4.dev0) (3.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.8.4.dev0) (2024.5.15)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers<=4.45.0,>=4.41.2->llamafactory==0.8.4.dev0) (0.19.1)\n",
            "Requirement already satisfied: tyro>=0.5.11 in /usr/local/lib/python3.10/dist-packages (from trl<=0.9.6,>=0.8.6->llamafactory==0.8.4.dev0) (0.8.10)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.8.4.dev0) (8.1.7)\n",
            "Requirement already satisfied: h11>=0.8 in /usr/local/lib/python3.10/dist-packages (from uvicorn->llamafactory==0.8.4.dev0) (0.14.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.8.4.dev0) (1.16.0)\n",
            "Requirement already satisfied: termcolor in /usr/local/lib/python3.10/dist-packages (from fire->llamafactory==0.8.4.dev0) (2.4.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk->llamafactory==0.8.4.dev0) (1.4.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.8.4.dev0) (3.8)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.8.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio>=4.0.0->llamafactory==0.8.4.dev0) (1.2.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (4.0.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.4.dev0) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio>=4.0.0->llamafactory==0.8.4.dev0) (1.0.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.32.2->datasets<=2.21.0,>=2.16.0->llamafactory==0.8.4.dev0) (3.3.2)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.4.dev0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.4.dev0) (13.8.0)\n",
            "Requirement already satisfied: docstring-parser>=0.16 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.8.4.dev0) (0.16)\n",
            "Requirement already satisfied: shtab>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from tyro>=0.5.11->trl<=0.9.6,>=0.8.6->llamafactory==0.8.4.dev0) (1.7.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.1->llamafactory==0.8.4.dev0) (1.3.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.4.dev0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.4.dev0) (2.16.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio>=4.0.0->llamafactory==0.8.4.dev0) (0.1.2)\n",
            "Building wheels for collected packages: llamafactory\n",
            "  Building editable for llamafactory (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llamafactory: filename=llamafactory-0.8.4.dev0-0.editable-py3-none-any.whl size=22339 sha256=536b77f3e83b5737e87cb8371b2bde42c6dbd78a67a78ab3fa371f1a52df9c15\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-3s4snx8a/wheels/de/aa/c5/27b5682c5592b7c0eecc3e208f176dedf6b11a61cf2a910b85\n",
            "Successfully built llamafactory\n",
            "Installing collected packages: llamafactory\n",
            "  Attempting uninstall: llamafactory\n",
            "    Found existing installation: llamafactory 0.8.4.dev0\n",
            "    Uninstalling llamafactory-0.8.4.dev0:\n",
            "      Successfully uninstalled llamafactory-0.8.4.dev0\n",
            "Successfully installed llamafactory-0.8.4.dev0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sRnfG978LEGC",
        "outputId": "cf5f3f7c-5289-451f-d4af-58f7f00bf303"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/LLaMA-Factory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LLama Board"
      ],
      "metadata": {
        "id": "XGN1wxjMPImg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "%cd ~/LLaMA-Factory/\n",
        "print(f\"Llama Board UI URL: {os.getenv('GRADIO_URL')}\")\n",
        "!GRADIO_SHARE=1 llamafactory-cli webui # Make GRADIO_SHARE=1 for enabling the Gradio Public URL."
      ],
      "metadata": {
        "id": "vTBrnnkvNAk0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Llama Factory CLI"
      ],
      "metadata": {
        "id": "aJTvP_-3PLF6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install liger-kernel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMd9n1KLQg1D",
        "outputId": "1902456d-6e99-4cff-95dc-9ac7d85c0d8b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting liger-kernel\n",
            "  Downloading liger_kernel-0.2.1-py3-none-any.whl.metadata (17 kB)\n",
            "Requirement already satisfied: torch>=2.1.2 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (2.4.0+cu121)\n",
            "Collecting triton>=2.3.0 (from liger-kernel)\n",
            "  Downloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.3 kB)\n",
            "Requirement already satisfied: transformers>=4.42.0 in /usr/local/lib/python3.10/dist-packages (from liger-kernel) (4.44.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.15.4)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (4.12.2)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (1.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=2.1.2->liger-kernel) (2024.6.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.24.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (2024.5.15)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers>=4.42.0->liger-kernel) (4.66.5)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=2.1.2->liger-kernel) (2.1.5)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (3.8)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers>=4.42.0->liger-kernel) (2024.8.30)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=2.1.2->liger-kernel) (1.3.0)\n",
            "Downloading liger_kernel-0.2.1-py3-none-any.whl (40 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.5/40.5 kB\u001b[0m \u001b[31m737.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (209.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m209.4/209.4 MB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: triton, liger-kernel\n",
            "Successfully installed liger-kernel-0.2.1 triton-3.0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "args = dict(\n",
        "  stage=\"sft\",                        # do supervised fine-tuning\n",
        "  do_train=True,\n",
        "  model_name_or_path=\"Qwen/Qwen2-VL-2B-Instruct\", # use bnb-4bit-quantized Llama-3-8B-Instruct model\n",
        "  dataset=\"mllm_demo,identity\",             # use alpaca and identity datasets\n",
        "  template=\"qwen2_vl\",                     # use llama3 prompt template\n",
        "  finetuning_type=\"lora\",                   # use LoRA adapters to save memory\n",
        "  lora_target=\"all\",                     # attach LoRA adapters to all linear layers\n",
        "  output_dir=\"qwen2vl_lora\",                  # the path to save LoRA adapters\n",
        "  per_device_train_batch_size=2,               # the batch size\n",
        "  gradient_accumulation_steps=4,               # the gradient accumulation steps\n",
        "  lr_scheduler_type=\"cosine\",                 # use cosine learning rate scheduler\n",
        "  logging_steps=10,                      # log every 10 steps\n",
        "  warmup_ratio=0.1,                      # use warmup scheduler\n",
        "  save_steps=1000,                      # save checkpoint every 1000 steps\n",
        "  learning_rate=5e-5,                     # the learning rate\n",
        "  num_train_epochs=2.0,                    # the epochs of training\n",
        "  max_samples=500,                      # use 500 examples in each dataset\n",
        "  max_grad_norm=1.0,                     # clip gradient norm to 1.0\n",
        "  loraplus_lr_ratio=16.0,                   # use LoRA+ algorithm with lambda=16.0\n",
        "  fp16=True,                # use liger kernel for efficient training\n",
        "  use_liger_kernel=True\n",
        ")\n",
        "\n",
        "json.dump(args, open(\"train_qwen2vl.json\", \"w\", encoding=\"utf-8\"), indent=2)\n",
        "\n",
        "!llamafactory-cli train train_qwen2vl.json"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "84XTJwoMIXxb",
        "outputId": "46c3df1b-bae3-4819-93e1-58473e0fd5c0"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2024-09-07 16:15:25.082481: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
            "2024-09-07 16:15:25.100456: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-09-07 16:15:25.121580: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-09-07 16:15:25.127946: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-09-07 16:15:25.143227: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 AVX512F AVX512_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-09-07 16:15:26.328857: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "09/07/2024 16:15:31 - INFO - llamafactory.hparams.parser - Process rank: 0, device: cuda:0, n_gpu: 1, distributed training: False, compute dtype: torch.float16\n",
            "[INFO|configuration_utils.py:672] 2024-09-07 16:15:31,848 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/config.json\n",
            "[INFO|configuration_utils.py:739] 2024-09-07 16:15:31,851 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"type\": \"mrope\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "tokenizer_config.json: 100% 4.19k/4.19k [00:00<00:00, 20.4MB/s]\n",
            "vocab.json: 100% 2.78M/2.78M [00:00<00:00, 11.0MB/s]\n",
            "merges.txt: 100% 1.67M/1.67M [00:00<00:00, 25.8MB/s]\n",
            "tokenizer.json: 100% 7.03M/7.03M [00:00<00:00, 50.0MB/s]\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:32,884 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2476] 2024-09-07 16:15:33,170 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "preprocessor_config.json: 100% 347/347 [00:00<00:00, 2.58MB/s]\n",
            "[INFO|image_processing_base.py:375] 2024-09-07 16:15:33,363 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:375] 2024-09-07 16:15:33,424 >> loading configuration file preprocessor_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/preprocessor_config.json\n",
            "[INFO|image_processing_base.py:429] 2024-09-07 16:15:33,425 >> Image processor Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,467 >> loading file vocab.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/vocab.json\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,468 >> loading file merges.txt from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/merges.txt\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,468 >> loading file tokenizer.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/tokenizer.json\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,468 >> loading file added_tokens.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,468 >> loading file special_tokens_map.json from cache at None\n",
            "[INFO|tokenization_utils_base.py:2212] 2024-09-07 16:15:33,468 >> loading file tokenizer_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2476] 2024-09-07 16:15:33,734 >> Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
            "chat_template.json: 100% 1.05k/1.05k [00:00<00:00, 7.65MB/s]\n",
            "[INFO|processing_utils.py:724] 2024-09-07 16:15:34,381 >> Processor Qwen2VLProcessor:\n",
            "- image_processor: Qwen2VLImageProcessor {\n",
            "  \"do_convert_rgb\": true,\n",
            "  \"do_normalize\": true,\n",
            "  \"do_rescale\": true,\n",
            "  \"do_resize\": true,\n",
            "  \"image_mean\": [\n",
            "    0.48145466,\n",
            "    0.4578275,\n",
            "    0.40821073\n",
            "  ],\n",
            "  \"image_processor_type\": \"Qwen2VLImageProcessor\",\n",
            "  \"image_std\": [\n",
            "    0.26862954,\n",
            "    0.26130258,\n",
            "    0.27577711\n",
            "  ],\n",
            "  \"max_pixels\": 12845056,\n",
            "  \"merge_size\": 2,\n",
            "  \"min_pixels\": 3136,\n",
            "  \"patch_size\": 14,\n",
            "  \"processor_class\": \"Qwen2VLProcessor\",\n",
            "  \"resample\": 3,\n",
            "  \"rescale_factor\": 0.00392156862745098,\n",
            "  \"size\": {\n",
            "    \"max_pixels\": 12845056,\n",
            "    \"min_pixels\": 3136\n",
            "  },\n",
            "  \"temporal_patch_size\": 2\n",
            "}\n",
            "\n",
            "- tokenizer: Qwen2TokenizerFast(name_or_path='Qwen/Qwen2-VL-2B-Instruct', vocab_size=151643, model_max_length=32768, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'eos_token': '<|im_end|>', 'pad_token': '<|endoftext|>', 'additional_special_tokens': ['<|im_start|>', '<|im_end|>', '<|object_ref_start|>', '<|object_ref_end|>', '<|box_start|>', '<|box_end|>', '<|quad_start|>', '<|quad_end|>', '<|vision_start|>', '<|vision_end|>', '<|vision_pad|>', '<|image_pad|>', '<|video_pad|>']}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
            "\t151643: AddedToken(\"<|endoftext|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151644: AddedToken(\"<|im_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151645: AddedToken(\"<|im_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151646: AddedToken(\"<|object_ref_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151647: AddedToken(\"<|object_ref_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151648: AddedToken(\"<|box_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151649: AddedToken(\"<|box_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151650: AddedToken(\"<|quad_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151651: AddedToken(\"<|quad_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151652: AddedToken(\"<|vision_start|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151653: AddedToken(\"<|vision_end|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151654: AddedToken(\"<|vision_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151655: AddedToken(\"<|image_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "\t151656: AddedToken(\"<|video_pad|>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
            "}\n",
            "\n",
            "{\n",
            "  \"processor_class\": \"Qwen2VLProcessor\"\n",
            "}\n",
            "\n",
            "09/07/2024 16:15:34 - INFO - llamafactory.data.template - Replace eos token: <|im_end|>\n",
            "09/07/2024 16:15:34 - INFO - llamafactory.data.loader - Loading dataset mllm_demo.json...\n",
            "Generating train split: 6 examples [00:00, 253.08 examples/s]\n",
            "Converting format of dataset: 100% 6/6 [00:00<00:00, 796.21 examples/s]\n",
            "09/07/2024 16:15:34 - INFO - llamafactory.data.loader - Loading dataset identity.json...\n",
            "Generating train split: 91 examples [00:00, 15629.24 examples/s]\n",
            "Converting format of dataset: 100% 91/91 [00:00<00:00, 8173.58 examples/s]\n",
            "Running tokenizer on dataset: 100% 97/97 [00:00<00:00, 626.54 examples/s]\n",
            "training example:\n",
            "input_ids:\n",
            "[151644, 8948, 198, 2610, 525, 264, 10950, 17847, 13, 151645, 198, 151644, 872, 198, 151652, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151655, 151653, 15191, 525, 807, 30, 151645, 198, 151644, 77091, 198, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, 198, 151644, 872, 198, 3838, 525, 807, 3730, 30, 151645, 198, 151644, 77091, 198, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645]\n",
            "inputs:\n",
            "<|im_start|>system\n",
            "You are a helpful assistant.<|im_end|>\n",
            "<|im_start|>user\n",
            "<|vision_start|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|image_pad|><|vision_end|>Who are they?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "They're Kane and Gretzka from Bayern Munich.<|im_end|>\n",
            "<|im_start|>user\n",
            "What are they doing?<|im_end|>\n",
            "<|im_start|>assistant\n",
            "They are celebrating on the soccer field.<|im_end|>\n",
            "label_ids:\n",
            "[-100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 2299, 45556, 323, 87552, 89, 4554, 504, 55591, 46204, 13, 151645, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, -100, 6865, 525, 31589, 389, 279, 22174, 2070, 13, 151645]\n",
            "labels:\n",
            "They're Kane and Gretzka from Bayern Munich.<|im_end|>They are celebrating on the soccer field.<|im_end|>\n",
            "[INFO|configuration_utils.py:672] 2024-09-07 16:15:35,014 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/config.json\n",
            "[INFO|configuration_utils.py:739] 2024-09-07 16:15:35,016 >> Model config Qwen2VLConfig {\n",
            "  \"_name_or_path\": \"Qwen/Qwen2-VL-2B-Instruct\",\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"type\": \"mrope\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "model.safetensors.index.json: 100% 56.4k/56.4k [00:00<00:00, 64.1MB/s]\n",
            "[INFO|modeling_utils.py:3693] 2024-09-07 16:15:35,338 >> loading weights file model.safetensors from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/model.safetensors.index.json\n",
            "Downloading shards:   0% 0/2 [00:00<?, ?it/s]\n",
            "model-00001-of-00002.safetensors:   0% 0.00/3.99G [00:00<?, ?B/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   0% 10.5M/3.99G [00:00<00:43, 92.1MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 31.5M/3.99G [00:00<00:27, 146MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   1% 52.4M/3.99G [00:00<00:23, 167MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 73.4M/3.99G [00:00<00:22, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   2% 94.4M/3.99G [00:00<00:21, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 115M/3.99G [00:00<00:20, 187MB/s] \u001b[A\n",
            "model-00001-of-00002.safetensors:   3% 136M/3.99G [00:00<00:20, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 157M/3.99G [00:00<00:20, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   4% 178M/3.99G [00:00<00:20, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   5% 199M/3.99G [00:01<00:20, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 231M/3.99G [00:01<00:19, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   6% 252M/3.99G [00:01<00:19, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 273M/3.99G [00:01<00:19, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   7% 294M/3.99G [00:01<00:19, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 315M/3.99G [00:01<00:19, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   8% 336M/3.99G [00:01<00:18, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 357M/3.99G [00:01<00:18, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:   9% 377M/3.99G [00:02<00:18, 197MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  10% 398M/3.99G [00:02<00:18, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 419M/3.99G [00:02<00:18, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  11% 440M/3.99G [00:02<00:18, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 461M/3.99G [00:02<00:18, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  12% 482M/3.99G [00:02<00:18, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 503M/3.99G [00:02<00:18, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  13% 524M/3.99G [00:02<00:18, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 545M/3.99G [00:02<00:18, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  14% 566M/3.99G [00:03<00:17, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 587M/3.99G [00:03<00:17, 195MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  15% 608M/3.99G [00:03<00:17, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 629M/3.99G [00:03<00:17, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  16% 650M/3.99G [00:03<00:17, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 671M/3.99G [00:03<00:17, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  17% 692M/3.99G [00:03<00:17, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 713M/3.99G [00:03<00:17, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  18% 734M/3.99G [00:03<00:16, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 755M/3.99G [00:03<00:16, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  19% 776M/3.99G [00:04<00:16, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  20% 797M/3.99G [00:04<00:16, 199MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 818M/3.99G [00:04<00:16, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  21% 839M/3.99G [00:04<00:16, 196MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 860M/3.99G [00:04<00:15, 198MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  22% 881M/3.99G [00:04<00:16, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 902M/3.99G [00:04<00:16, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  23% 923M/3.99G [00:04<00:16, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 944M/3.99G [00:04<00:15, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  24% 965M/3.99G [00:05<00:20, 148MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 986M/3.99G [00:05<00:19, 158MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  25% 1.01G/3.99G [00:05<00:18, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.03G/3.99G [00:05<00:17, 169MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  26% 1.05G/3.99G [00:05<00:17, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.07G/3.99G [00:05<00:16, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  27% 1.09G/3.99G [00:05<00:16, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.11G/3.99G [00:05<00:16, 177MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  28% 1.13G/3.99G [00:06<00:16, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.15G/3.99G [00:06<00:15, 179MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  29% 1.17G/3.99G [00:06<00:15, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.20G/3.99G [00:06<00:15, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  30% 1.22G/3.99G [00:06<00:15, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  31% 1.24G/3.99G [00:06<00:15, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.26G/3.99G [00:06<00:14, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  32% 1.28G/3.99G [00:06<00:14, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.30G/3.99G [00:07<00:14, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  33% 1.32G/3.99G [00:07<00:14, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.34G/3.99G [00:07<00:14, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  34% 1.36G/3.99G [00:07<00:14, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.38G/3.99G [00:07<00:14, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  35% 1.41G/3.99G [00:07<00:14, 181MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.43G/3.99G [00:07<00:14, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  36% 1.45G/3.99G [00:07<00:13, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.47G/3.99G [00:07<00:13, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  37% 1.49G/3.99G [00:08<00:13, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.51G/3.99G [00:08<00:13, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  38% 1.53G/3.99G [00:08<00:13, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.55G/3.99G [00:08<00:13, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  39% 1.57G/3.99G [00:08<00:13, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.59G/3.99G [00:08<00:12, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  40% 1.61G/3.99G [00:08<00:12, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  41% 1.64G/3.99G [00:08<00:12, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.66G/3.99G [00:08<00:12, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  42% 1.68G/3.99G [00:09<00:12, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.70G/3.99G [00:09<00:11, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  43% 1.72G/3.99G [00:09<00:11, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.74G/3.99G [00:09<00:11, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  44% 1.76G/3.99G [00:09<00:11, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.78G/3.99G [00:09<00:11, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  45% 1.80G/3.99G [00:09<00:11, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.82G/3.99G [00:09<00:11, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  46% 1.85G/3.99G [00:09<00:11, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.87G/3.99G [00:10<00:11, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  47% 1.89G/3.99G [00:10<00:11, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.91G/3.99G [00:10<00:11, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  48% 1.93G/3.99G [00:10<00:11, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.95G/3.99G [00:10<00:11, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  49% 1.97G/3.99G [00:10<00:10, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 1.99G/3.99G [00:10<00:10, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  50% 2.01G/3.99G [00:10<00:10, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  51% 2.03G/3.99G [00:10<00:10, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.06G/3.99G [00:11<00:10, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  52% 2.08G/3.99G [00:11<00:10, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.11G/3.99G [00:11<00:09, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  53% 2.13G/3.99G [00:11<00:09, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.15G/3.99G [00:11<00:09, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  54% 2.17G/3.99G [00:11<00:09, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.19G/3.99G [00:11<00:09, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  55% 2.21G/3.99G [00:11<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  56% 2.23G/3.99G [00:12<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.25G/3.99G [00:12<00:09, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  57% 2.28G/3.99G [00:12<00:09, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.30G/3.99G [00:12<00:08, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  58% 2.32G/3.99G [00:12<00:08, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.34G/3.99G [00:12<00:08, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  59% 2.36G/3.99G [00:12<00:08, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.38G/3.99G [00:12<00:08, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  60% 2.40G/3.99G [00:12<00:08, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.42G/3.99G [00:13<00:08, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  61% 2.44G/3.99G [00:13<00:12, 120MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.46G/3.99G [00:13<00:11, 133MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  62% 2.49G/3.99G [00:13<00:10, 143MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.51G/3.99G [00:13<00:09, 153MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  63% 2.53G/3.99G [00:13<00:09, 159MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.55G/3.99G [00:13<00:08, 164MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  64% 2.57G/3.99G [00:14<00:08, 168MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.59G/3.99G [00:14<00:08, 165MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  65% 2.61G/3.99G [00:14<00:08, 170MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  66% 2.63G/3.99G [00:14<00:07, 172MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.65G/3.99G [00:14<00:07, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  67% 2.67G/3.99G [00:14<00:07, 175MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.69G/3.99G [00:14<00:07, 174MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  68% 2.72G/3.99G [00:14<00:07, 176MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.74G/3.99G [00:15<00:07, 178MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  69% 2.76G/3.99G [00:15<00:06, 180MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.78G/3.99G [00:15<00:06, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  70% 2.80G/3.99G [00:15<00:06, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.82G/3.99G [00:15<00:06, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  71% 2.84G/3.99G [00:15<00:06, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.86G/3.99G [00:15<00:05, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  72% 2.88G/3.99G [00:15<00:05, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.90G/3.99G [00:15<00:05, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  73% 2.93G/3.99G [00:16<00:05, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.95G/3.99G [00:16<00:05, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  74% 2.97G/3.99G [00:16<00:05, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 2.99G/3.99G [00:16<00:05, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  75% 3.01G/3.99G [00:16<00:05, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  76% 3.03G/3.99G [00:16<00:05, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.05G/3.99G [00:16<00:05, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  77% 3.07G/3.99G [00:16<00:04, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.09G/3.99G [00:16<00:04, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  78% 3.11G/3.99G [00:17<00:04, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.14G/3.99G [00:17<00:04, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  79% 3.16G/3.99G [00:17<00:04, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.18G/3.99G [00:17<00:04, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  80% 3.20G/3.99G [00:17<00:04, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.22G/3.99G [00:17<00:04, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  81% 3.24G/3.99G [00:17<00:04, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.26G/3.99G [00:17<00:03, 190MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  82% 3.28G/3.99G [00:17<00:03, 192MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.30G/3.99G [00:18<00:03, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  83% 3.32G/3.99G [00:18<00:03, 193MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.34G/3.99G [00:18<00:03, 194MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  84% 3.37G/3.99G [00:18<00:03, 191MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.39G/3.99G [00:18<00:03, 189MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  85% 3.41G/3.99G [00:18<00:03, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.43G/3.99G [00:18<00:03, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  86% 3.45G/3.99G [00:18<00:02, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  87% 3.47G/3.99G [00:18<00:02, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.49G/3.99G [00:19<00:02, 182MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  88% 3.51G/3.99G [00:19<00:02, 188MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.53G/3.99G [00:19<00:02, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  89% 3.55G/3.99G [00:19<00:02, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.58G/3.99G [00:19<00:02, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  90% 3.60G/3.99G [00:19<00:02, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.62G/3.99G [00:19<00:02, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  91% 3.64G/3.99G [00:19<00:01, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.66G/3.99G [00:19<00:01, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  92% 3.68G/3.99G [00:20<00:01, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.70G/3.99G [00:20<00:01, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  93% 3.72G/3.99G [00:20<00:01, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.74G/3.99G [00:20<00:01, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  94% 3.76G/3.99G [00:20<00:01, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.79G/3.99G [00:20<00:01, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  95% 3.81G/3.99G [00:20<00:00, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.83G/3.99G [00:20<00:00, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  96% 3.85G/3.99G [00:20<00:00, 183MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  97% 3.87G/3.99G [00:21<00:00, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.89G/3.99G [00:21<00:00, 186MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  98% 3.91G/3.99G [00:21<00:00, 185MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.93G/3.99G [00:21<00:00, 184MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors:  99% 3.95G/3.99G [00:21<00:00, 187MB/s]\u001b[A\n",
            "model-00001-of-00002.safetensors: 100% 3.99G/3.99G [00:21<00:00, 183MB/s]\n",
            "Downloading shards:  50% 1/2 [00:21<00:21, 21.96s/it]\n",
            "model-00002-of-00002.safetensors:   0% 0.00/429M [00:00<?, ?B/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:   7% 31.5M/429M [00:00<00:01, 210MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  15% 62.9M/429M [00:00<00:01, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  20% 83.9M/429M [00:00<00:01, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  24% 105M/429M [00:00<00:01, 188MB/s] \u001b[A\n",
            "model-00002-of-00002.safetensors:  29% 126M/429M [00:00<00:01, 185MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  34% 147M/429M [00:00<00:01, 184MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  39% 168M/429M [00:00<00:01, 189MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  44% 189M/429M [00:00<00:01, 191MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  49% 210M/429M [00:01<00:01, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  54% 231M/429M [00:01<00:01, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  59% 252M/429M [00:01<00:00, 186MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  63% 273M/429M [00:01<00:00, 192MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  68% 294M/429M [00:01<00:00, 193MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  73% 315M/429M [00:01<00:00, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  78% 336M/429M [00:01<00:00, 194MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  83% 357M/429M [00:01<00:00, 198MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  88% 377M/429M [00:01<00:00, 197MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors:  93% 398M/429M [00:02<00:00, 199MB/s]\u001b[A\n",
            "model-00002-of-00002.safetensors: 100% 429M/429M [00:02<00:00, 193MB/s]\n",
            "Downloading shards: 100% 2/2 [00:24<00:00, 12.15s/it]\n",
            "[INFO|modeling_utils.py:1613] 2024-09-07 16:15:59,637 >> Instantiating Qwen2VLForConditionalGeneration model under default dtype torch.float16.\n",
            "[INFO|configuration_utils.py:1091] 2024-09-07 16:15:59,639 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645\n",
            "}\n",
            "\n",
            "Loading checkpoint shards: 100% 2/2 [00:02<00:00,  1.35s/it]\n",
            "[INFO|modeling_utils.py:4522] 2024-09-07 16:16:03,067 >> All model checkpoint weights were used when initializing Qwen2VLForConditionalGeneration.\n",
            "\n",
            "[INFO|modeling_utils.py:4530] 2024-09-07 16:16:03,067 >> All the weights of Qwen2VLForConditionalGeneration were initialized from the model checkpoint at Qwen/Qwen2-VL-2B-Instruct.\n",
            "If your task is similar to the task the model of the checkpoint was trained on, you can already use Qwen2VLForConditionalGeneration for predictions without further training.\n",
            "generation_config.json: 100% 272/272 [00:00<00:00, 2.57MB/s]\n",
            "[INFO|configuration_utils.py:1046] 2024-09-07 16:16:03,159 >> loading configuration file generation_config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/generation_config.json\n",
            "[INFO|configuration_utils.py:1091] 2024-09-07 16:16:03,159 >> Generate config GenerationConfig {\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"do_sample\": true,\n",
            "  \"eos_token_id\": [\n",
            "    151645,\n",
            "    151643\n",
            "  ],\n",
            "  \"pad_token_id\": 151643,\n",
            "  \"temperature\": 0.01,\n",
            "  \"top_k\": 1,\n",
            "  \"top_p\": 0.001\n",
            "}\n",
            "\n",
            "09/07/2024 16:16:03 - INFO - llamafactory.model.model_utils.checkpointing - Gradient checkpointing enabled.\n",
            "09/07/2024 16:16:03 - INFO - llamafactory.model.model_utils.attention - Using torch SDPA for faster training and inference.\n",
            "09/07/2024 16:16:03 - INFO - llamafactory.model.adapter - Upcasting trainable params to float32.\n",
            "09/07/2024 16:16:03 - INFO - llamafactory.model.adapter - Fine-tuning method: LoRA\n",
            "09/07/2024 16:16:03 - INFO - llamafactory.model.model_utils.misc - Found linear modules: gate_proj,o_proj,up_proj,q_proj,k_proj,down_proj,v_proj\n",
            "09/07/2024 16:16:04 - INFO - llamafactory.model.loader - trainable params: 9,232,384 || all params: 2,218,217,984 || trainable%: 0.4162\n",
            "/usr/local/lib/python3.10/dist-packages/accelerate/accelerator.py:488: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
            "  self.scaler = torch.cuda.amp.GradScaler(**kwargs)\n",
            "[INFO|trainer.py:667] 2024-09-07 16:16:04,419 >> Using auto half precision backend\n",
            "09/07/2024 16:16:04 - INFO - llamafactory.train.trainer_utils - Using LoRA+ optimizer with loraplus lr ratio 16.00.\n",
            "[INFO|trainer.py:2182] 2024-09-07 16:16:05,056 >> ***** Running training *****\n",
            "[INFO|trainer.py:2183] 2024-09-07 16:16:05,057 >>   Num examples = 97\n",
            "[INFO|trainer.py:2184] 2024-09-07 16:16:05,057 >>   Num Epochs = 2\n",
            "[INFO|trainer.py:2185] 2024-09-07 16:16:05,057 >>   Instantaneous batch size per device = 2\n",
            "[INFO|trainer.py:2188] 2024-09-07 16:16:05,057 >>   Total train batch size (w. parallel, distributed & accumulation) = 8\n",
            "[INFO|trainer.py:2189] 2024-09-07 16:16:05,057 >>   Gradient Accumulation steps = 4\n",
            "[INFO|trainer.py:2190] 2024-09-07 16:16:05,057 >>   Total optimization steps = 24\n",
            "[INFO|trainer.py:2191] 2024-09-07 16:16:05,063 >>   Number of trainable parameters = 9,232,384\n",
            "  0% 0/24 [00:00<?, ?it/s]/usr/local/lib/python3.10/dist-packages/torch/utils/checkpoint.py:295: FutureWarning: `torch.cpu.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cpu', args...)` instead.\n",
            "  with torch.enable_grad(), device_autocast_ctx, torch.cpu.amp.autocast(**ctx.cpu_autocast_kwargs):  # type: ignore[attr-defined]\n",
            "{'loss': 1.7835, 'grad_norm': 1.239060640335083, 'learning_rate': 3.7500000000000003e-05, 'epoch': 0.82}\n",
            "{'loss': 0.9139, 'grad_norm': 1.374374270439148, 'learning_rate': 4.344030642100133e-06, 'epoch': 1.63}\n",
            "100% 24/24 [00:36<00:00,  1.42s/it][INFO|trainer.py:3639] 2024-09-07 16:16:41,851 >> Saving model checkpoint to qwen2vl_lora/checkpoint-24\n",
            "[INFO|configuration_utils.py:672] 2024-09-07 16:16:41,968 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/config.json\n",
            "[INFO|configuration_utils.py:739] 2024-09-07 16:16:41,970 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"type\": \"mrope\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2647] 2024-09-07 16:16:42,100 >> tokenizer config file saved in qwen2vl_lora/checkpoint-24/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2656] 2024-09-07 16:16:42,100 >> Special tokens file saved in qwen2vl_lora/checkpoint-24/special_tokens_map.json\n",
            "[INFO|trainer.py:2442] 2024-09-07 16:16:42,451 >> \n",
            "\n",
            "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
            "\n",
            "\n",
            "{'train_runtime': 37.3885, 'train_samples_per_second': 5.189, 'train_steps_per_second': 0.642, 'train_loss': 1.2561362286408742, 'epoch': 1.96}\n",
            "100% 24/24 [00:37<00:00,  1.56s/it]\n",
            "[INFO|image_processing_base.py:258] 2024-09-07 16:16:42,454 >> Image processor saved in qwen2vl_lora/preprocessor_config.json\n",
            "[INFO|trainer.py:3639] 2024-09-07 16:16:42,454 >> Saving model checkpoint to qwen2vl_lora\n",
            "[INFO|configuration_utils.py:672] 2024-09-07 16:16:42,563 >> loading configuration file config.json from cache at /root/.cache/huggingface/hub/models--Qwen--Qwen2-VL-2B-Instruct/snapshots/3c86da475a9bcc0876910f022ecdd476e621e636/config.json\n",
            "[INFO|configuration_utils.py:739] 2024-09-07 16:16:42,565 >> Model config Qwen2VLConfig {\n",
            "  \"architectures\": [\n",
            "    \"Qwen2VLForConditionalGeneration\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.0,\n",
            "  \"bos_token_id\": 151643,\n",
            "  \"eos_token_id\": 151645,\n",
            "  \"hidden_act\": \"silu\",\n",
            "  \"hidden_size\": 1536,\n",
            "  \"image_token_id\": 151655,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 8960,\n",
            "  \"max_position_embeddings\": 32768,\n",
            "  \"max_window_layers\": 28,\n",
            "  \"model_type\": \"qwen2_vl\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 28,\n",
            "  \"num_key_value_heads\": 2,\n",
            "  \"rms_norm_eps\": 1e-06,\n",
            "  \"rope_scaling\": {\n",
            "    \"mrope_section\": [\n",
            "      16,\n",
            "      24,\n",
            "      24\n",
            "    ],\n",
            "    \"type\": \"mrope\"\n",
            "  },\n",
            "  \"rope_theta\": 1000000.0,\n",
            "  \"sliding_window\": 32768,\n",
            "  \"tie_word_embeddings\": true,\n",
            "  \"torch_dtype\": \"bfloat16\",\n",
            "  \"transformers_version\": \"4.45.0.dev0\",\n",
            "  \"use_cache\": true,\n",
            "  \"use_sliding_window\": false,\n",
            "  \"video_token_id\": 151656,\n",
            "  \"vision_config\": {\n",
            "    \"hidden_size\": 1536,\n",
            "    \"in_chans\": 3,\n",
            "    \"model_type\": \"qwen2_vl\",\n",
            "    \"spatial_patch_size\": 14\n",
            "  },\n",
            "  \"vision_end_token_id\": 151653,\n",
            "  \"vision_start_token_id\": 151652,\n",
            "  \"vision_token_id\": 151654,\n",
            "  \"vocab_size\": 151936\n",
            "}\n",
            "\n",
            "[INFO|tokenization_utils_base.py:2647] 2024-09-07 16:16:42,645 >> tokenizer config file saved in qwen2vl_lora/tokenizer_config.json\n",
            "[INFO|tokenization_utils_base.py:2656] 2024-09-07 16:16:42,645 >> Special tokens file saved in qwen2vl_lora/special_tokens_map.json\n",
            "***** train metrics *****\n",
            "  epoch                    =     1.9592\n",
            "  total_flos               =   153413GF\n",
            "  train_loss               =     1.2561\n",
            "  train_runtime            = 0:00:37.38\n",
            "  train_samples_per_second =      5.189\n",
            "  train_steps_per_second   =      0.642\n",
            "[INFO|modelcard.py:449] 2024-09-07 16:16:42,818 >> Dropping the following result as it does not have all the necessary fields:\n",
            "{'task': {'name': 'Causal Language Modeling', 'type': 'text-generation'}}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0qdC9ilfQVWu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}